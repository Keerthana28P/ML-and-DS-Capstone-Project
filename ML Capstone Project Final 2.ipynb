{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "549b6207-efd6-4126-8de0-2eefba552ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4d82629-4f4e-4b95-abc1-8b9765783d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load Dataset\n",
    "df = pd.read_csv(\"retail_store_inventory.csv\")\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.sort_values(['Store ID', 'Product ID', 'Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f063fc45-27a4-4c17-b5cb-3166d6854cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Encode Categorical Columns\n",
    "cat_cols = ['Store ID', 'Product ID', 'Category', 'Region', 'Weather Condition', 'Seasonality']\n",
    "le_dict = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    le_dict[col] = le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb263869-cc09-40d7-a4c2-38ec4f63d00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keert\\AppData\\Local\\Temp\\ipykernel_12336\\2390427045.py:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(['Store ID', 'Product ID']).apply(create_lag_features)\n"
     ]
    }
   ],
   "source": [
    "# 4. Feature Engineering\n",
    "df['day_of_week'] = df['Date'].dt.dayofweek\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['year'] = df['Date'].dt.year\n",
    "\n",
    "def create_lag_features(group):\n",
    "    group['lag_7'] = group['Units Sold'].shift(7)\n",
    "    group['lag_14'] = group['Units Sold'].shift(14)\n",
    "    group['rolling_mean_7'] = group['Units Sold'].shift(1).rolling(window=7).mean()\n",
    "    group['rolling_std_7'] = group['Units Sold'].shift(1).rolling(window=7).std()\n",
    "    return group\n",
    "\n",
    "df = df.groupby(['Store ID', 'Product ID']).apply(create_lag_features)\n",
    "df.dropna(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4bad02e-68ed-4235-ae90-28ed9fc7c8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Top 5 Features: ['Demand Forecast', 'Inventory Level', 'Competitor Pricing', 'rolling_mean_7', 'rolling_std_7']\n"
     ]
    }
   ],
   "source": [
    "# 5. Feature Selection (Dynamic: Keep top 5 features based on importance)\n",
    "all_features = [\n",
    "    'Store ID', 'Product ID', 'Category', 'Region', 'Inventory Level',\n",
    "    'Units Ordered', 'Demand Forecast', 'Price', 'Discount',\n",
    "    'Weather Condition', 'Holiday/Promotion', 'Competitor Pricing',\n",
    "    'Seasonality', 'day_of_week', 'month', 'year',\n",
    "    'lag_7', 'lag_14', 'rolling_mean_7', 'rolling_std_7'\n",
    "]\n",
    "X_full = df[all_features]\n",
    "y = df['Units Sold']\n",
    "\n",
    "# Pre-split to prevent leakage\n",
    "X_train_full, X_val_full, y_train_full, y_val_full = train_test_split(X_full, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Fit temporary model for importance\n",
    "selector_model = xgb.XGBRegressor(random_state=42)\n",
    "selector_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Get top 5 important features\n",
    "importances = selector_model.feature_importances_\n",
    "importance_df = pd.DataFrame({'feature': X_full.columns, 'importance': importances})\n",
    "importance_df.sort_values(by='importance', ascending=False, inplace=True)\n",
    "\n",
    "top_5_features = importance_df['feature'].iloc[:5].tolist()\n",
    "print(f\"Selected Top 5 Features: {top_5_features}\")\n",
    "\n",
    "# Final feature set\n",
    "X = X_full[top_5_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02d9b202-61aa-494d-95cc-24483ccac802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf32706b-2d13-4cc3-af09-559e08056399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47ee1167-53dd-4e5d-965a-eebe237b8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Model Training\n",
    "params = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.1, 0.05]\n",
    "}\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "gs = GridSearchCV(xgb_model, params, cv=3, scoring='neg_root_mean_squared_error')\n",
    "gs.fit(X_train_scaled, y_train)\n",
    "best_model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5d8bf85-56d0-4693-8810-ecce12248eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 8.302586038357672\n",
      "Test RMSE: 8.37406106665489\n",
      "Test MAE: 7.158233215951853\n",
      "Test R2: 0.9941690564155579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keert\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\keert\\Anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 9. Evaluation\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "print(\"Train RMSE:\", mean_squared_error(y_train, best_model.predict(X_train_scaled), squared=False))\n",
    "print(\"Test RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "print(\"Test MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"Test R2:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a952e71-4e84-4e33-9167-3449f28486d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Save Models\n",
    "joblib.dump(best_model, \"xgb_inventory_model.pkl\")\n",
    "joblib.dump(scaler, \"inventory_scaler.pkl\")\n",
    "joblib.dump(le_dict, \"le_dict.pkl\")\n",
    "joblib.dump(top_5_features, \"selected_features.pkl\")\n",
    "df.to_csv(\"updated_inventory_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ab25e96-6020-48f4-94f5-de7e7fd7da3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Prediction Function\n",
    "def predict_inventory(user_input):\n",
    "    # Load assets\n",
    "    model = joblib.load(\"xgb_inventory_model.pkl\")\n",
    "    scaler = joblib.load(\"inventory_scaler.pkl\")\n",
    "    le_dict = joblib.load(\"le_dict.pkl\")\n",
    "    selected_features = joblib.load(\"selected_features.pkl\")\n",
    "    df_hist = pd.read_csv(\"updated_inventory_dataset.csv\")\n",
    "    df_hist['Date'] = pd.to_datetime(df_hist['Date'])\n",
    "\n",
    "    # Encode categorical columns\n",
    "    input_df = pd.DataFrame([user_input])\n",
    "    for col in cat_cols:\n",
    "        value=input_df[col].iloc[0]\n",
    "        encoder=le_dict[col]\n",
    "        if value not in encoder.classes_:\n",
    "            encoder.classes_=np.append(encoder.classes_,value)\n",
    "        input_df[col]=encoder.transform([value])\n",
    "\n",
    "    # Add time features\n",
    "    input_df['Date'] = pd.to_datetime(input_df['Date'])\n",
    "    input_df['day_of_week'] = input_df['Date'].dt.dayofweek\n",
    "    input_df['month'] = input_df['Date'].dt.month\n",
    "    input_df['year'] = input_df['Date'].dt.year\n",
    "\n",
    "    # Merge with history to compute rolling features\n",
    "    match_df = df_hist[\n",
    "        (df_hist['Store ID'] == input_df['Store ID'].iloc[0]) &\n",
    "        (df_hist['Product ID'] == input_df['Product ID'].iloc[0])\n",
    "    ].copy()\n",
    "    combined = pd.concat([match_df, input_df], ignore_index=True)\n",
    "    combined.sort_values('Date', inplace=True)\n",
    "    combined = create_lag_features(combined)\n",
    "    input_row = combined.iloc[-1:][selected_features]\n",
    "\n",
    "     # Scale and Predict\n",
    "    input_scaled = scaler.transform(input_row)\n",
    "    predicted_sales = model.predict(input_scaled)[0]\n",
    "\n",
    "    # Inventory Recommendation\n",
    "    safety_stock = predicted_sales * 0.15\n",
    "    reorder_point = predicted_sales * 7 + safety_stock\n",
    "    recommended_stock = predicted_sales + safety_stock\n",
    "\n",
    "    # Dynamic Pricing\n",
    "    demand_gap = predicted_sales - user_input['Inventory Level']\n",
    "    price_adjustment = 0.1 * (demand_gap / predicted_sales) if predicted_sales != 0 else 0\n",
    "    competitor_adjustment = (user_input['Competitor Pricing'] - user_input['Price']) * 0.2\n",
    "    new_price = user_input['Price'] + user_input['Price'] * price_adjustment + competitor_adjustment\n",
    "    new_price = round(max(new_price, 0.01), 2)\n",
    "\n",
    "    print(\"\\n--- Inventory & Pricing Recommendation ---\")\n",
    "    print(\"Predicted Sales:\", round(predicted_sales, 2))\n",
    "    print(\"Safety Stock:\", round(safety_stock, 2))\n",
    "    print(\"Recommended Stock Level:\", round(recommended_stock, 2))\n",
    "    print(\"Reorder Point:\", round(reorder_point, 2))\n",
    "    print(\"Suggested Price:\", round(new_price, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e24c7491-7e80-4525-ba4a-39a60da7fe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Inventory & Pricing Recommendation ---\n",
      "Predicted Sales: 47.59\n",
      "Safety Stock: 7.14\n",
      "Recommended Stock Level: 54.72\n",
      "Reorder Point: 340.24\n",
      "Suggested Price: 19.23\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 12. Sample Real-Time Prediction\n",
    "sample_input = {\n",
    "    'Store ID': 'S001',\n",
    "    'Product ID': 'P0001',\n",
    "    'Category': 'Groceries',\n",
    "    'Region': 'North',\n",
    "    'Inventory Level': 231,\n",
    "    'Units Ordered': 55,\n",
    "    'Demand Forecast': 135.47,\n",
    "    'Price': 33.5,\n",
    "    'Discount': 20,\n",
    "    'Weather Condition': 'Rainy',\n",
    "    'Holiday/Promotion': 0,\n",
    "    'Competitor Pricing': 26.69,\n",
    "    'Seasonality': 'Autumn',\n",
    "    'Date': '2022-01-01'\n",
    "}\n",
    "result = predict_inventory(sample_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbdb131-f898-4df4-afbd-4cb0b1825f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
